{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu0qeQSX8CMmHOzGvO+dcI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohil344/ANN/blob/main/Graduate_Admission_Prediction_using_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "a4swiHcxNz4C"
      },
      "outputs": [],
      "source": [
        "#Inpuit file can be foun on Kaggle- https://www.kaggle.com/code/campusx/gre-admission-prediction/input\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "soTr4lziVbei"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/Admission_Predict_Ver1.1.csv')"
      ],
      "metadata": {
        "id": "seMF0-YFa4Mx"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "xqbpCTB1bEug",
        "outputId": "b2f3d5c0-86dc-4905-99cf-41ddd16a1292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
              "0             1        337          118                  4  4.5   4.5  9.65   \n",
              "1             2        324          107                  4  4.0   4.5  8.87   \n",
              "2             3        316          104                  3  3.0   3.5  8.00   \n",
              "3             4        322          110                  3  3.5   2.5  8.67   \n",
              "4             5        314          103                  2  2.0   3.0  8.21   \n",
              "..          ...        ...          ...                ...  ...   ...   ...   \n",
              "495         496        332          108                  5  4.5   4.0  9.02   \n",
              "496         497        337          117                  5  5.0   5.0  9.87   \n",
              "497         498        330          120                  5  4.5   5.0  9.56   \n",
              "498         499        312          103                  4  4.0   5.0  8.43   \n",
              "499         500        327          113                  4  4.5   4.5  9.04   \n",
              "\n",
              "     Research  Chance of Admit   \n",
              "0           1              0.92  \n",
              "1           1              0.76  \n",
              "2           1              0.72  \n",
              "3           1              0.80  \n",
              "4           0              0.65  \n",
              "..        ...               ...  \n",
              "495         1              0.87  \n",
              "496         1              0.96  \n",
              "497         1              0.93  \n",
              "498         0              0.73  \n",
              "499         0              0.84  \n",
              "\n",
              "[500 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdfcba01-efb2-40bb-b6a0-3c162a8f5d77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>496</td>\n",
              "      <td>332</td>\n",
              "      <td>108</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.02</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>497</td>\n",
              "      <td>337</td>\n",
              "      <td>117</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>498</td>\n",
              "      <td>330</td>\n",
              "      <td>120</td>\n",
              "      <td>5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.56</td>\n",
              "      <td>1</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>499</td>\n",
              "      <td>312</td>\n",
              "      <td>103</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.43</td>\n",
              "      <td>0</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>500</td>\n",
              "      <td>327</td>\n",
              "      <td>113</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.04</td>\n",
              "      <td>0</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdfcba01-efb2-40bb-b6a0-3c162a8f5d77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdfcba01-efb2-40bb-b6a0-3c162a8f5d77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdfcba01-efb2-40bb-b6a0-3c162a8f5d77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "\n",
        "#no null values"
      ],
      "metadata": {
        "id": "VDo7sGsObGcB",
        "outputId": "3cb41b8c-c3af-4118-918d-0cf7a250c800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 9 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Serial No.         500 non-null    int64  \n",
            " 1   GRE Score          500 non-null    int64  \n",
            " 2   TOEFL Score        500 non-null    int64  \n",
            " 3   University Rating  500 non-null    int64  \n",
            " 4   SOP                500 non-null    float64\n",
            " 5   LOR                500 non-null    float64\n",
            " 6   CGPA               500 non-null    float64\n",
            " 7   Research           500 non-null    int64  \n",
            " 8   Chance of Admit    500 non-null    float64\n",
            "dtypes: float64(4), int64(5)\n",
            "memory usage: 35.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()\n",
        "\n",
        "#no duplicated row"
      ],
      "metadata": {
        "id": "3q-JtD6cbK-A",
        "outputId": "06b2e5f4-1ce5-4b76-fac0-bbaffa12ac06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "axHWRSQ3bSX3",
        "outputId": "fe80c00a-a988-4066-e4da-c81c6d230850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Serial No.'],inplace=True)  #eliminating serial no"
      ],
      "metadata": {
        "id": "Hk9ok0KYbZ1g"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "OoJT3pV3dJuE",
        "outputId": "b2e73b6f-2fc4-40b1-8219-141bca7914b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
              "0        337          118                  4  4.5   4.5  9.65         1   \n",
              "1        324          107                  4  4.0   4.5  8.87         1   \n",
              "2        316          104                  3  3.0   3.5  8.00         1   \n",
              "3        322          110                  3  3.5   2.5  8.67         1   \n",
              "4        314          103                  2  2.0   3.0  8.21         0   \n",
              "\n",
              "   Chance of Admit   \n",
              "0              0.92  \n",
              "1              0.76  \n",
              "2              0.72  \n",
              "3              0.80  \n",
              "4              0.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed3c2ee8-0534-4fd8-ad24-8ec59b9bc81e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed3c2ee8-0534-4fd8-ad24-8ec59b9bc81e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed3c2ee8-0534-4fd8-ad24-8ec59b9bc81e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed3c2ee8-0534-4fd8-ad24-8ec59b9bc81e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,0:-1]\n",
        "y=df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "TpnP-gn1bwBq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "3VKX5XxGcCkx"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n"
      ],
      "metadata": {
        "id": "6VEmDZqlgC6c",
        "outputId": "0afb756d-3546-4a0c-9599-7cf085694b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "4uanbItlgMYW",
        "outputId": "55eaa9d8-1dd9-41c1-b25a-d043b1a7b166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()"
      ],
      "metadata": {
        "id": "UDwKr_UigN6s"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled=scaler.fit_transform(X_train)\n",
        "X_test_scaled=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "1oJqp5SXgVjG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled"
      ],
      "metadata": {
        "id": "aHKh2I8VgioV",
        "outputId": "9bb1d76e-fda3-4882-c04b-fc4af46cd950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
              "        0.        ],\n",
              "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
              "        1.        ],\n",
              "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
              "        1.        ],\n",
              "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
              "        1.        ],\n",
              "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "metadata": {
        "id": "8PRJg9LAhJPm"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n"
      ],
      "metadata": {
        "id": "dFooTztMhUhP"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.add(Dense(7,activation='relu',input_dim=7))\n",
        " model.add(Dense(1,activation='linear'))"
      ],
      "metadata": {
        "id": "5dqY82qkhYnH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "8HRh1uk9hpLn",
        "outputId": "98f2c9ff-ce95-4916-d970-8cc8faf93075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64\n",
            "Trainable params: 64\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error',optimizer='Adam')"
      ],
      "metadata": {
        "id": "LmfaFRonhr5A"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train_scaled,y_train,epochs=500,validation_split=0.2)"
      ],
      "metadata": {
        "id": "n_4r_JIth4Pn",
        "outputId": "508952fb-074a-45f2-d0a7-f83053a31b60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0082\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0082\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0080\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0081\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0079\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0080\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0079\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0078\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0078\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0077\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0076\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0076\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0076\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 0.0075\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0075\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0074\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0075\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0073\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0073\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0072\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0068 - val_loss: 0.0073\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0072\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 0.0071\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0071\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0070\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0070\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0069\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0070\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0069\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0068\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0068\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0068\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0068\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0067\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0067\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0066\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0066\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0065\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0065\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0065\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0064\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0064\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0064\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0064\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0063\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0063\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0062\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0063\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0062\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0062\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0061\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0060\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0061\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0061\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0061\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0059\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0059\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0058\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0058\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0058\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0058\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0058\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0058\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0057\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0057\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0057\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0057\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0055\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0054\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0055\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0055\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0055\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0054\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0055\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0054\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0054\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - val_loss: 0.0053\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - val_loss: 0.0054\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0054\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0053\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0052\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0053\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0053\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0052\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0053\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0052\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0051\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0052\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0050\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0049\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0049\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0049\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0048\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0048\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0048\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0048\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0047\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0047\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0047\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0047\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0047\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0047\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0047\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0047\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0045\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0045\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0045\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0044\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0044\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0045\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0045\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0046\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0043\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0043\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0043\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0042\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0042\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0041\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0041\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0042\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0042\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0042\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0042\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0042\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0040\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0040\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0037\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0036\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0036\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0035\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0036\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "4iYzbdoyiGVA",
        "outputId": "110f6c23-a83a-4c66-dfb1-d91c7a8f7344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "DgVlAp3DiMWp"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "pA8nUBSziTOo",
        "outputId": "58de1d80-33fe-4f5a-fe5b-597bbfb6e560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5966478139914515"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "#val loss and training loss seems to be close so we can model is trained well just need to focus on r2 score"
      ],
      "metadata": {
        "id": "dQDhhjWkqnmy",
        "outputId": "97448388-8ca6-442a-94e8-17ca0292fa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f58e2f543d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e5FrNGVCrPmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}